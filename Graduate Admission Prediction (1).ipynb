{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e26693d9-2242-4841-8b99-549aaed63722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e949b14-097d-44a7-8909-6424d83dc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42003985-806a-449e-b054-e471475841ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9545f699-7a8a-43de-8d48-be4ef0bbf1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  \n",
       "\n",
       "[400 rows x 9 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786999aa-5b5c-442e-bebc-b1a6ec92ca57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef14742a-7e42-4330-8505-24f79a29b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'Serial No.', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9af7996e-fe93-421d-bc08-57c79c1a38c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0          337          118                  4  4.5   4.5  9.65         1   \n",
       "1          324          107                  4  4.0   4.5  8.87         1   \n",
       "2          316          104                  3  3.0   3.5  8.00         1   \n",
       "3          322          110                  3  3.5   2.5  8.67         1   \n",
       "4          314          103                  2  2.0   3.0  8.21         0   \n",
       "..         ...          ...                ...  ...   ...   ...       ...   \n",
       "395        324          110                  3  3.5   3.5  9.04         1   \n",
       "396        325          107                  3  3.0   3.5  9.11         1   \n",
       "397        330          116                  4  5.0   4.5  9.45         1   \n",
       "398        312          103                  3  3.5   4.0  8.78         0   \n",
       "399        333          117                  4  5.0   4.0  9.66         1   \n",
       "\n",
       "     Chance of Admit   \n",
       "0                0.92  \n",
       "1                0.76  \n",
       "2                0.72  \n",
       "3                0.80  \n",
       "4                0.65  \n",
       "..                ...  \n",
       "395              0.82  \n",
       "396              0.84  \n",
       "397              0.91  \n",
       "398              0.67  \n",
       "399              0.95  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc8abbdf-8fb1-402e-a26e-02b7deb97de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,0:-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f94bf9f-2337-4505-aef5-be3fc11415a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "449a0387-19e5-4e20-839a-8de2b09c3d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "395    0.82\n",
       "396    0.84\n",
       "397    0.91\n",
       "398    0.67\n",
       "399    0.95\n",
       "Name: Chance of Admit , Length: 400, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "859f0197-8c5c-4abb-866b-35673533c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train,y_test = train_test_split(x,y, test_size = 0.2, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ec6ffad-ecd4-4f01-9af4-c0e76d4780c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>301</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>334</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>305</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>307</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>318</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "93         301           97                  2  3.0   3.0  7.88         1\n",
       "23         334          119                  5  5.0   4.5  9.70         1\n",
       "299        305          112                  3  3.0   3.5  8.65         0\n",
       "13         307          109                  3  4.0   3.0  8.00         1\n",
       "90         318          106                  2  4.0   4.0  7.92         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[320 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69b00657-0257-4df2-bba7-04fcea36c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e23fe1a4-4171-4b55-99e5-882ee98cf678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22      , 0.17857143, 0.25      , ..., 0.42857143, 0.25      ,\n",
       "        1.        ],\n",
       "       [0.88      , 0.96428571, 1.        , ..., 0.85714286, 0.91911765,\n",
       "        1.        ],\n",
       "       [0.3       , 0.71428571, 0.5       , ..., 0.57142857, 0.53308824,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.70220588,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.74632353,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.22058824,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9745e8f-11bd-489d-94fd-c66a448f01d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "932072d1-a4b6-47e7-96c4-f1e391f5e2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91979\\OneDrive\\Desktop\\python.project\\Annaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(7, activation = 'relu', input_dim = 7))\n",
    "model.add(Dense(7, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fa4d65e7-994a-4361-999b-ba295e48f7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c53bd286-2a46-4724-b479-19a68f032a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error' , optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "26bc9fc1-bac5-46b8-a0c3-a8af2faacdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.6542 - val_loss: 0.6153\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5366 - val_loss: 0.5181\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4514 - val_loss: 0.4280\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3705 - val_loss: 0.3443\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2957 - val_loss: 0.2690\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2282 - val_loss: 0.2023\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1747 - val_loss: 0.1450\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1238 - val_loss: 0.0980\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0801 - val_loss: 0.0620\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0481 - val_loss: 0.0356\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0302 - val_loss: 0.0189\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0170 - val_loss: 0.0124\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0126 - val_loss: 0.0112\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0108 - val_loss: 0.0095\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0094 - val_loss: 0.0091\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0085 - val_loss: 0.0078\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0076 - val_loss: 0.0073\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0077 - val_loss: 0.0068\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0078 - val_loss: 0.0064\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0075 - val_loss: 0.0061\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0040 - val_loss: 0.0036\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs =100 , validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c841a815-965d-4f1e-a1b8-6a7bc2fe488f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e67cf883-e824-417c-b73f-6228a32d1a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8037334040181109"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dcf8a57d-f2b2-43a9-8d6c-c10204453dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a538119670>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975f9e4-4948-4c4a-8ae5-cb62e38ef3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
